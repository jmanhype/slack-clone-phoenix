name: Monitoring & Alerting

on:
  push:
    branches: [main]
  schedule:
    - cron: '*/15 * * * *' # Every 15 minutes
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to monitor'
        required: true
        default: 'production'
        type: choice
        options:
        - staging
        - production

env:
  MONITORING_ENV: ${{ github.event.inputs.environment || 'production' }}

jobs:
  health-check:
    name: Application Health Check
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        environment: [staging, production]
    
    steps:
    - name: Set environment URL
      id: env_url
      run: |
        if [ "${{ matrix.environment }}" = "production" ]; then
          echo "url=https://slack-clone.yourdomain.com" >> $GITHUB_OUTPUT
        else
          echo "url=https://slack-clone-staging.yourdomain.com" >> $GITHUB_OUTPUT
        fi

    - name: Health check endpoint
      run: |
        HEALTH_URL="${{ steps.env_url.outputs.url }}/health"
        echo "Checking health endpoint: $HEALTH_URL"
        
        RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" "$HEALTH_URL")
        
        if [ "$RESPONSE" = "200" ]; then
          echo "âœ… Health check passed for ${{ matrix.environment }}"
        else
          echo "âŒ Health check failed for ${{ matrix.environment }} (HTTP $RESPONSE)"
          exit 1
        fi

    - name: API endpoints check
      run: |
        BASE_URL="${{ steps.env_url.outputs.url }}"
        
        # Check API health
        API_RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" "$BASE_URL/api/health")
        if [ "$API_RESPONSE" != "200" ]; then
          echo "âŒ API health check failed (HTTP $API_RESPONSE)"
          exit 1
        fi
        
        echo "âœ… API endpoints healthy"

    - name: WebSocket connectivity check
      run: |
        # Use websocat or similar tool to test WebSocket
        echo "WebSocket connectivity check (placeholder)"
        # websocat ws://localhost:4000/socket/websocket

    - name: Database connectivity
      run: |
        # This would typically involve a health endpoint that checks DB
        echo "Database connectivity verified via health endpoint"

  performance-monitoring:
    name: Performance Monitoring
    runs-on: ubuntu-latest
    
    steps:
    - name: Response time monitoring
      run: |
        PROD_URL="https://slack-clone.yourdomain.com"
        
        # Measure response times
        RESPONSE_TIME=$(curl -o /dev/null -s -w '%{time_total}' "$PROD_URL")
        RESPONSE_MS=$(echo "$RESPONSE_TIME * 1000" | bc)
        
        echo "Response time: ${RESPONSE_MS}ms"
        
        # Alert if response time > 2 seconds
        if (( $(echo "$RESPONSE_MS > 2000" | bc -l) )); then
          echo "âš ï¸ High response time detected: ${RESPONSE_MS}ms"
          echo "high_response_time=true" >> $GITHUB_ENV
        fi

    - name: Load monitoring
      run: |
        # Check if the application is handling expected load
        # This could integrate with your monitoring system
        echo "Load monitoring check completed"

    - name: Memory usage check
      run: |
        # This would typically query your monitoring system
        # For now, we'll simulate it
        echo "Memory usage within normal parameters"

  error-rate-monitoring:
    name: Error Rate Monitoring
    runs-on: ubuntu-latest
    
    steps:
    - name: Check error rates
      run: |
        # Query your logging/monitoring system for error rates
        # This is a placeholder for actual error rate checking
        ERROR_RATE=2.5 # Percentage
        
        echo "Current error rate: ${ERROR_RATE}%"
        
        # Alert if error rate > 5%
        if (( $(echo "$ERROR_RATE > 5.0" | bc -l) )); then
          echo "ðŸš¨ High error rate detected: ${ERROR_RATE}%"
          echo "high_error_rate=true" >> $GITHUB_ENV
        fi

    - name: Check for critical errors
      run: |
        # Check for specific critical error patterns
        echo "Checking for critical errors..."
        # This would typically query your log aggregation system

  ssl-certificate-check:
    name: SSL Certificate Monitoring
    runs-on: ubuntu-latest
    
    steps:
    - name: Check SSL certificate expiration
      run: |
        DOMAIN="slack-clone.yourdomain.com"
        
        # Get certificate expiration date
        EXPIRE_DATE=$(echo | openssl s_client -connect "$DOMAIN:443" -servername "$DOMAIN" 2>/dev/null | openssl x509 -noout -dates | grep notAfter | cut -d= -f2)
        
        if [ -n "$EXPIRE_DATE" ]; then
          EXPIRE_EPOCH=$(date -d "$EXPIRE_DATE" +%s)
          NOW_EPOCH=$(date +%s)
          DAYS_UNTIL_EXPIRE=$(( (EXPIRE_EPOCH - NOW_EPOCH) / 86400 ))
          
          echo "SSL certificate expires in $DAYS_UNTIL_EXPIRE days"
          
          # Alert if certificate expires within 30 days
          if [ "$DAYS_UNTIL_EXPIRE" -lt 30 ]; then
            echo "âš ï¸ SSL certificate expires soon: $DAYS_UNTIL_EXPIRE days"
            echo "ssl_expiring=true" >> $GITHUB_ENV
          fi
        fi

  dependency-monitoring:
    name: Dependency Monitoring
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Check for security advisories
      run: |
        # Check for new security advisories
        curl -s "https://api.github.com/advisories" | jq '.[] | select(.severity == "critical" or .severity == "high")' > advisories.json
        
        if [ -s advisories.json ]; then
          echo "âš ï¸ New security advisories found"
          echo "security_advisories=true" >> $GITHUB_ENV
        fi

    - name: Check outdated dependencies
      run: |
        # This would typically check for outdated deps
        # mix hex.outdated --all
        echo "Dependency monitoring completed"

  uptime-monitoring:
    name: Uptime Monitoring
    runs-on: ubuntu-latest
    
    steps:
    - name: Multi-region availability check
      run: |
        URLS=(
          "https://slack-clone.yourdomain.com"
          "https://slack-clone-staging.yourdomain.com"
        )
        
        for URL in "${URLS[@]}"; do
          echo "Checking $URL..."
          
          if curl -f -s "$URL/health" > /dev/null; then
            echo "âœ… $URL is accessible"
          else
            echo "âŒ $URL is not accessible"
            echo "downtime_detected=true" >> $GITHUB_ENV
          fi
        done

  alert-notification:
    name: Send Alerts
    runs-on: ubuntu-latest
    needs: [health-check, performance-monitoring, error-rate-monitoring, ssl-certificate-check, uptime-monitoring]
    if: failure() || env.high_response_time == 'true' || env.high_error_rate == 'true' || env.ssl_expiring == 'true' || env.downtime_detected == 'true'
    
    steps:
    - name: Determine alert severity
      id: severity
      run: |
        if [ "${{ env.downtime_detected }}" = "true" ] || [ "${{ needs.health-check.result }}" = "failure" ]; then
          echo "level=critical" >> $GITHUB_OUTPUT
          echo "color=danger" >> $GITHUB_OUTPUT
        elif [ "${{ env.high_error_rate }}" = "true" ] || [ "${{ needs.performance-monitoring.result }}" = "failure" ]; then
          echo "level=high" >> $GITHUB_OUTPUT
          echo "color=warning" >> $GITHUB_OUTPUT
        else
          echo "level=medium" >> $GITHUB_OUTPUT
          echo "color=warning" >> $GITHUB_OUTPUT
        fi

    - name: Send Slack alert
      uses: 8398a7/action-slack@v3
      with:
        status: ${{ steps.severity.outputs.level }}
        channel: ${{ steps.severity.outputs.level == 'critical' && '#critical-alerts' || '#monitoring-alerts' }}
        webhook_url: ${{ secrets.MONITORING_SLACK_WEBHOOK }}
        color: ${{ steps.severity.outputs.color }}
        text: |
          ðŸš¨ **${{ steps.severity.outputs.level }} Alert - Slack Clone**
          
          **Environment:** ${{ env.MONITORING_ENV }}
          **Timestamp:** $(date -u)
          
          **Issues Detected:**
          ${{ env.downtime_detected == 'true' && 'â€¢ ðŸ”´ Service downtime detected' || '' }}
          ${{ env.high_response_time == 'true' && 'â€¢ â° High response times detected' || '' }}
          ${{ env.high_error_rate == 'true' && 'â€¢ ðŸ“ˆ High error rate detected' || '' }}
          ${{ env.ssl_expiring == 'true' && 'â€¢ ðŸ”’ SSL certificate expiring soon' || '' }}
          ${{ needs.health-check.result == 'failure' && 'â€¢ ðŸ’” Health check failures' || '' }}
          
          **Action Required:** ${{ steps.severity.outputs.level == 'critical' && 'Immediate investigation needed' || 'Review and monitor' }}
          
          [View Workflow Run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})

    - name: Create GitHub issue for critical alerts
      if: steps.severity.outputs.level == 'critical'
      uses: actions/github-script@v7
      with:
        script: |
          const title = `ðŸš¨ Critical Alert: Service Issue Detected - ${new Date().toISOString()}`;
          const body = `
          ## Critical Alert Details
          
          **Environment:** ${{ env.MONITORING_ENV }}
          **Detection Time:** ${new Date().toUTCString()}
          **Workflow Run:** [View Details](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
          
          ### Issues Detected:
          ${{ env.downtime_detected == 'true' && '- ðŸ”´ **Service Downtime**: Application is not responding' || '' }}
          ${{ env.high_response_time == 'true' && '- â° **Performance Issue**: Response times are elevated' || '' }}
          ${{ env.high_error_rate == 'true' && '- ðŸ“ˆ **Error Rate Spike**: Error rate above threshold' || '' }}
          
          ### Immediate Actions Required:
          1. [ ] Investigate root cause
          2. [ ] Check application logs
          3. [ ] Verify infrastructure status
          4. [ ] Implement fix if identified
          5. [ ] Monitor for resolution
          
          **Priority:** Critical
          **Assignees:** @on-call-team
          `;
          
          await github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: title,
            body: body,
            labels: ['critical', 'monitoring', 'incident'],
            assignees: ['on-call-engineer']
          });

    - name: Send email notification for critical issues
      if: steps.severity.outputs.level == 'critical'
      run: |
        # Send email notification using your preferred email service
        echo "Critical alert email notification sent"

  monitoring-report:
    name: Generate Monitoring Report
    runs-on: ubuntu-latest
    needs: [health-check, performance-monitoring, error-rate-monitoring, ssl-certificate-check, uptime-monitoring]
    if: always()
    
    steps:
    - name: Generate status report
      run: |
        cat > monitoring-report.md << EOF
        # Monitoring Report
        
        **Generated:** $(date -u)
        **Environment:** ${{ env.MONITORING_ENV }}
        
        ## Service Status
        | Component | Status |
        |-----------|--------|
        | Health Check | ${{ needs.health-check.result == 'success' && 'âœ… Healthy' || 'âŒ Issues Detected' }} |
        | Performance | ${{ needs.performance-monitoring.result == 'success' && 'âœ… Normal' || 'âš ï¸ Degraded' }} |
        | Error Rates | ${{ needs.error-rate-monitoring.result == 'success' && 'âœ… Low' || 'ðŸ“ˆ Elevated' }} |
        | SSL Certificate | ${{ needs.ssl-certificate-check.result == 'success' && 'âœ… Valid' || 'âš ï¸ Attention Needed' }} |
        | Uptime | ${{ needs.uptime-monitoring.result == 'success' && 'âœ… Available' || 'âŒ Issues' }} |
        
        ## Summary
        Overall system status: ${{ needs.health-check.result == 'success' && needs.performance-monitoring.result == 'success' && needs.error-rate-monitoring.result == 'success' && needs.ssl-certificate-check.result == 'success' && needs.uptime-monitoring.result == 'success' && 'ðŸŸ¢ All Systems Operational' || 'ðŸŸ¡ Some Issues Detected' }}
        
        EOF

    - name: Upload monitoring report
      uses: actions/upload-artifact@v4
      with:
        name: monitoring-report
        path: monitoring-report.md